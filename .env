# Minecraft AI Research Environment Configuration

# LLM Model to use (must be available in Ollama)
# Options: llama3.1:8b, mistral:7b, codellama:7b, etc.
LLM_MODEL=llama3.1:8b

# Ollama host (for local development outside Docker)
# OLLAMA_HOST=http://localhost:11434

# Minecraft server settings (optional overrides)
# MINECRAFT_VERSION=1.20.4
# MINECRAFT_MEMORY=2G

# Agent decision interval in milliseconds (default: 5000)
# DECISION_INTERVAL=5000

# Debug mode (set to 1 to enable verbose logging)
# DEBUG=1
